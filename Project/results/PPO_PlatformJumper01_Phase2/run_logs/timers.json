{
    "name": "root",
    "gauges": {
        "PlatformJumper.Policy.Entropy.mean": {
            "value": 2.0156147480010986,
            "min": 1.9923006296157837,
            "max": 2.0611774921417236,
            "count": 16
        },
        "PlatformJumper.Policy.Entropy.sum": {
            "value": 60480.5390625,
            "min": 59826.53515625,
            "max": 62088.375,
            "count": 16
        },
        "PlatformJumper.Environment.EpisodeLength.mean": {
            "value": 237.3984375,
            "min": 237.3984375,
            "max": 538.1090909090909,
            "count": 16
        },
        "PlatformJumper.Environment.EpisodeLength.sum": {
            "value": 30387.0,
            "min": 27243.0,
            "max": 31148.0,
            "count": 16
        },
        "PlatformJumper.Step.mean": {
            "value": 479875.0,
            "min": 29983.0,
            "max": 479875.0,
            "count": 16
        },
        "PlatformJumper.Step.sum": {
            "value": 479875.0,
            "min": 29983.0,
            "max": 479875.0,
            "count": 16
        },
        "PlatformJumper.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.2711105942726135,
            "min": 0.0010326728224754333,
            "max": 0.3626267910003662,
            "count": 16
        },
        "PlatformJumper.Policy.ExtrinsicValueEstimate.sum": {
            "value": 80.24873352050781,
            "min": 0.26746225357055664,
            "max": 91.74457550048828,
            "count": 16
        },
        "PlatformJumper.Policy.CuriosityValueEstimate.mean": {
            "value": 0.5019835233688354,
            "min": 0.20263677835464478,
            "max": 0.5414190292358398,
            "count": 16
        },
        "PlatformJumper.Policy.CuriosityValueEstimate.sum": {
            "value": 148.58712768554688,
            "min": 52.48292541503906,
            "max": 154.24526977539062,
            "count": 16
        },
        "PlatformJumper.Environment.CumulativeReward.mean": {
            "value": 0.5670312618021853,
            "min": -0.1636538257320913,
            "max": 0.6786666808029016,
            "count": 16
        },
        "PlatformJumper.Environment.CumulativeReward.sum": {
            "value": 72.58000151067972,
            "min": -8.599998967722058,
            "max": 81.44000169634819,
            "count": 16
        },
        "PlatformJumper.Policy.ExtrinsicReward.mean": {
            "value": 0.5670312618021853,
            "min": -0.1636538257320913,
            "max": 0.6786666808029016,
            "count": 16
        },
        "PlatformJumper.Policy.ExtrinsicReward.sum": {
            "value": 72.58000151067972,
            "min": -8.599998967722058,
            "max": 81.44000169634819,
            "count": 16
        },
        "PlatformJumper.Policy.CuriosityReward.mean": {
            "value": 1.12550291183652,
            "min": 0.9497564252186567,
            "max": 1.6413690454131107,
            "count": 16
        },
        "PlatformJumper.Policy.CuriosityReward.sum": {
            "value": 144.06437271507457,
            "min": 51.928189968690276,
            "max": 174.1730770561844,
            "count": 16
        },
        "PlatformJumper.Losses.PolicyLoss.mean": {
            "value": 0.06741106676041193,
            "min": 0.0650877552540719,
            "max": 0.07332719213149679,
            "count": 16
        },
        "PlatformJumper.Losses.PolicyLoss.sum": {
            "value": 0.9437549346457671,
            "min": 0.9112285735570066,
            "max": 1.0461729192347775,
            "count": 16
        },
        "PlatformJumper.Losses.ValueLoss.mean": {
            "value": 0.00857551771921516,
            "min": 0.002553102026034876,
            "max": 0.00868334547807795,
            "count": 16
        },
        "PlatformJumper.Losses.ValueLoss.sum": {
            "value": 0.12005724806901223,
            "min": 0.03574342836448826,
            "max": 0.1215668366930913,
            "count": 16
        },
        "PlatformJumper.Policy.LearningRate.mean": {
            "value": 2.088737875185714e-05,
            "min": 2.088737875185714e-05,
            "max": 0.00029071140309619995,
            "count": 16
        },
        "PlatformJumper.Policy.LearningRate.sum": {
            "value": 0.00029242330252599995,
            "min": 0.00029242330252599995,
            "max": 0.0038261101246299992,
            "count": 16
        },
        "PlatformJumper.Policy.Epsilon.mean": {
            "value": 0.10696242857142857,
            "min": 0.10696242857142857,
            "max": 0.19690380000000002,
            "count": 16
        },
        "PlatformJumper.Policy.Epsilon.sum": {
            "value": 1.497474,
            "min": 1.497474,
            "max": 2.685407,
            "count": 16
        },
        "PlatformJumper.Policy.Beta.mean": {
            "value": 0.0007055466142857145,
            "min": 0.0007055466142857145,
            "max": 0.00969068962,
            "count": 16
        },
        "PlatformJumper.Policy.Beta.sum": {
            "value": 0.009877652600000002,
            "min": 0.009877652600000002,
            "max": 0.127549463,
            "count": 16
        },
        "PlatformJumper.Losses.CuriosityForwardLoss.mean": {
            "value": 0.22255341651006824,
            "min": 0.096210057063842,
            "max": 0.27078831958628835,
            "count": 16
        },
        "PlatformJumper.Losses.CuriosityForwardLoss.sum": {
            "value": 3.1157478311409554,
            "min": 1.250730741829946,
            "max": 3.791036474208037,
            "count": 16
        },
        "PlatformJumper.Losses.CuriosityInverseLoss.mean": {
            "value": 2.273219289879004,
            "min": 2.066008910984775,
            "max": 2.4592258885857605,
            "count": 16
        },
        "PlatformJumper.Losses.CuriosityInverseLoss.sum": {
            "value": 31.825070058306054,
            "min": 28.483927531196272,
            "max": 34.42916244020065,
            "count": 16
        },
        "PlatformJumper.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 16
        },
        "PlatformJumper.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 16
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1641227279",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Ortwin\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\mlagents-learn ..\\Config\\PPO_PlatformJumper.yaml --run-id=PPO_PlatformJumper01_Phase2 --initialize-from=PPO_PlatformJumper_Phase1",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.5",
        "end_time_seconds": "1641228688"
    },
    "total": 1409.2639655,
    "count": 1,
    "self": 0.014835000000175569,
    "children": {
        "run_training.setup": {
            "total": 0.1485394000000002,
            "count": 1,
            "self": 0.1485394000000002
        },
        "TrainerController.start_learning": {
            "total": 1409.1005911,
            "count": 1,
            "self": 1.2089981999865813,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.8573104,
                    "count": 1,
                    "self": 11.8573104
                },
                "TrainerController.advance": {
                    "total": 1395.8953130000136,
                    "count": 56854,
                    "self": 1.3683515999771316,
                    "children": {
                        "env_step": {
                            "total": 849.5553059000267,
                            "count": 56854,
                            "self": 642.5329132000495,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 206.23974430000482,
                                    "count": 56854,
                                    "self": 3.966677200011503,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 202.2730670999933,
                                            "count": 55614,
                                            "self": 91.4747976999968,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 110.79826939999651,
                                                    "count": 55614,
                                                    "self": 110.79826939999651
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.7826483999723344,
                                    "count": 56854,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1396.6947164,
                                            "count": 56854,
                                            "is_parallel": true,
                                            "self": 830.4645472000309,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0017174999999998164,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00044200000000138573,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0012754999999984307,
                                                            "count": 16,
                                                            "is_parallel": true,
                                                            "self": 0.0012754999999984307
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 566.2284516999691,
                                                    "count": 56854,
                                                    "is_parallel": true,
                                                    "self": 16.69076819995996,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 10.2231764000009,
                                                            "count": 56854,
                                                            "is_parallel": true,
                                                            "self": 10.2231764000009
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 482.50808579999585,
                                                            "count": 56854,
                                                            "is_parallel": true,
                                                            "self": 482.50808579999585
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 56.80642130001245,
                                                            "count": 56854,
                                                            "is_parallel": true,
                                                            "self": 15.777550400108701,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 41.02887089990375,
                                                                    "count": 909664,
                                                                    "is_parallel": true,
                                                                    "self": 41.02887089990375
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 544.9716555000098,
                            "count": 56854,
                            "self": 2.002125800020167,
                            "children": {
                                "process_trajectory": {
                                    "total": 81.961464199988,
                                    "count": 56854,
                                    "self": 81.83569449998791,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.1257697000000917,
                                            "count": 1,
                                            "self": 0.1257697000000917
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 461.00806550000163,
                                    "count": 236,
                                    "self": 150.6750709000059,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 310.33299459999574,
                                            "count": 11379,
                                            "self": 310.33299459999574
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.999998044600943e-07,
                    "count": 1,
                    "self": 8.999998044600943e-07
                },
                "TrainerController._save_models": {
                    "total": 0.13896859999999833,
                    "count": 1,
                    "self": 0.030720900000005713,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.10824769999999262,
                            "count": 1,
                            "self": 0.10824769999999262
                        }
                    }
                }
            }
        }
    }
}